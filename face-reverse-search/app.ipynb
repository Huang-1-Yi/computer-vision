{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c0898b4-6d59-4767-ab49-a887d8adfad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Load YuNet model for face detection\n",
    "yunet = cv2.FaceDetectorYN.create(\n",
    "    model=\"face_detection_yunet_2023mar.onnx\",  # Pre-trained ONNX model path\n",
    "    config=\"\",\n",
    "    input_size=(320, 320),  # Input image size\n",
    "    score_threshold=0.9,\n",
    "    nms_threshold=0.3,\n",
    "    top_k=5000\n",
    ")\n",
    "\n",
    "# Load FaceNet model for embeddings\n",
    "facenet_model = \"VGG-Face\"  # You can also use 'Facenet512' for higher accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b67511c6-9a8b-4a9f-b281-a3f7c3db89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_faces(image_path, output_folder=None, return_boxes=False):\n",
    "    \"\"\"\n",
    "    Detect faces in an image, crop them, optionally save them, and optionally return face bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        output_folder (str, optional): Folder to save cropped face images. If None, faces are not saved.\n",
    "        return_boxes (bool): Whether to return face bounding boxes.\n",
    "\n",
    "    Returns:\n",
    "        list: List of cropped face images.\n",
    "        list (optional): List of bounding boxes [(x, y, width, height), ...].\n",
    "    \"\"\"\n",
    "    # Read the input image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not read {image_path}\")\n",
    "        return [] if not return_boxes else ([], [])\n",
    "\n",
    "    # Set YuNet input size\n",
    "    height, width = img.shape[:2]\n",
    "    yunet.setInputSize((width, height))\n",
    "    \n",
    "    # Detect faces\n",
    "    _, faces = yunet.detect(img)\n",
    "\n",
    "    cropped_faces = []\n",
    "    face_boxes = []\n",
    "\n",
    "    if faces is not None:\n",
    "        for idx, face in enumerate(faces):\n",
    "            x, y, w, h = face[:4].astype(int)\n",
    "            # Crop the face from the image\n",
    "            cropped_face = img[y:y+h, x:x+w]\n",
    "            cropped_faces.append(cropped_face)\n",
    "            face_boxes.append((x, y, w, h))  # Store the bounding box coordinates\n",
    "            \n",
    "            # Save the cropped face if output_folder is provided\n",
    "            if output_folder:\n",
    "                os.makedirs(output_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "                face_filename = os.path.join(\n",
    "                    output_folder, f\"{os.path.splitext(os.path.basename(image_path))[0]}_face_{idx}.jpg\"\n",
    "                )\n",
    "                cv2.imwrite(face_filename, cropped_face)\n",
    "\n",
    "    if return_boxes:\n",
    "        return cropped_faces, face_boxes\n",
    "    return cropped_faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "282137d8-d0c1-4a81-aa1c-fd1637ec9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the pre-trained FaceNet model\n",
    "def get_embeddings(face_images):\n",
    "    embeddings = []\n",
    "    for face_img in face_images:\n",
    "        face_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        embedding = DeepFace.represent(img_path=face_rgb, model_name=facenet_model,enforce_detection=False)[0]['embedding']\n",
    "        embeddings.append(np.array(embedding, dtype=np.float32))\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a64829ac-af17-4efb-86e8-299c46c45552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_store_images(image_folder, face_folder, index, faiss_index_path, metadata_path):\n",
    "    \"\"\"\n",
    "    Process images to detect faces, save cropped faces, and store embeddings in FAISS and metadata.\n",
    "\n",
    "    Args:\n",
    "        image_folder (str): Path to the folder containing input images.\n",
    "        face_folder (str): Path to the folder to save cropped faces.\n",
    "        index (faiss.IndexFlatL2): FAISS index for storing embeddings.\n",
    "        faiss_index_path (str): Path to save the FAISS index.\n",
    "        metadata_path (str): Path to save photo ID metadata.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    os.makedirs(face_folder, exist_ok=True)  # Ensure the face folder exists\n",
    "\n",
    "    photo_ids = []  # Keep track of photo IDs, cropped face filenames, and embeddings\n",
    "\n",
    "    for photo_id, image_file in enumerate(os.listdir(image_folder)):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        faces = detect_and_crop_faces(image_path, face_folder, return_boxes=False)\n",
    "        if faces:\n",
    "            embeddings = get_embeddings(faces)\n",
    "            for idx, (face, embedding) in enumerate(zip(faces, embeddings)):\n",
    "                # Save the embedding to the FAISS index\n",
    "                index.add(np.expand_dims(embedding, axis=0))\n",
    "                \n",
    "                # Save the cropped face image\n",
    "                cropped_face_filename = f\"{os.path.splitext(image_file)[0]}_face_{idx}.jpg\"\n",
    "                cropped_face_path = os.path.join(face_folder, cropped_face_filename)\n",
    "                cv2.imwrite(cropped_face_path, face)\n",
    "\n",
    "                # Add metadata entry\n",
    "                photo_ids.append({\n",
    "                    \"original_image\": image_file,\n",
    "                    \"cropped_face\": cropped_face_filename,\n",
    "                    \"embedding\": embedding.tolist()  # Convert embedding to a list for JSON serialization\n",
    "                })\n",
    "    \n",
    "    # Save the FAISS index\n",
    "    faiss.write_index(index, faiss_index_path)\n",
    "    print(f\"FAISS index saved to {faiss_index_path}\")\n",
    "\n",
    "    # Save metadata as JSON\n",
    "    with open(metadata_path, 'w') as metadata_file:\n",
    "        json.dump(photo_ids, metadata_file, indent=4)\n",
    "    print(f\"Metadata saved to {metadata_path}\")\n",
    "\n",
    "    print(f\"Processed {len(photo_ids)} faces.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "520c4434-dc2c-4511-b926-09771bcd9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faiss_and_metadata(faiss_index_path, metadata_path):\n",
    "    \"\"\"\n",
    "    Load the FAISS index and metadata for reuse.\n",
    "\n",
    "    Args:\n",
    "        faiss_index_path (str): Path to the FAISS index.\n",
    "        metadata_path (str): Path to the metadata file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Loaded FAISS index and metadata.\n",
    "    \"\"\"\n",
    "    # Load FAISS index\n",
    "    index = faiss.read_index(faiss_index_path)\n",
    "    print(f\"Loaded FAISS index with {index.ntotal} embeddings.\")\n",
    "\n",
    "    # Load metadata\n",
    "    with open(metadata_path, 'r') as metadata_file:\n",
    "        photo_ids = json.load(metadata_file)\n",
    "    print(f\"Loaded metadata for {len(photo_ids)} faces.\")\n",
    "\n",
    "    return index, photo_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f9cf7e8-3daf-4c56-b6c5-414b405a9208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read hum/H&M/.DS_Store\n",
      "FAISS index saved to hum/faiss_index.bin\n",
      "Metadata saved to hum/photo_ids.json\n",
      "Processed 146 faces.\n"
     ]
    }
   ],
   "source": [
    "# Define the FAISS index\n",
    "embedding_dimension = 4096  # FaceNet output dimension\n",
    "index = faiss.IndexFlatL2(embedding_dimension)  # L2 (Euclidean) distance\n",
    "\n",
    "# Folder and file paths\n",
    "image_folder = \"hum/H&M\"\n",
    "face_folder = \"hum/cropped_faces\"\n",
    "faiss_index_path = \"hum/faiss_index.bin\"\n",
    "metadata_path = \"hum/photo_ids.json\"\n",
    "\n",
    "# Process images and store data\n",
    "process_and_store_images(image_folder, face_folder, index, faiss_index_path, metadata_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d6db8b6-eee5-4400-9906-870cd58e85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_faces(query_image, faiss_index_path, metadata_path, top_k=5):\n",
    "    \"\"\"\n",
    "    Search for similar faces to the query image using the stored FAISS index and metadata.\n",
    "\n",
    "    Args:\n",
    "        query_image (str): Path to the query image.\n",
    "        faiss_index_path (str): Path to the FAISS index file.\n",
    "        metadata_path (str): Path to the metadata JSON file.\n",
    "        top_k (int): Number of top matches to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the FAISS index\n",
    "    index = faiss.read_index(faiss_index_path)\n",
    "    print(f\"Loaded FAISS index from {faiss_index_path}\")\n",
    "\n",
    "    # Load the photo IDs metadata\n",
    "    with open(metadata_path, 'r') as metadata_file:\n",
    "        photo_ids = json.load(metadata_file)\n",
    "    print(f\"Loaded metadata from {metadata_path}\")\n",
    "\n",
    "    # Detect faces in the query image\n",
    "    faces = detect_and_crop_faces(query_image)\n",
    "    if not faces:\n",
    "        print(\"No face detected in query image.\")\n",
    "        return\n",
    "\n",
    "    # Generate embeddings for the detected faces\n",
    "    query_embeddings = get_embeddings(faces)\n",
    "\n",
    "    # Search the FAISS index for each query embedding\n",
    "    for query_embedding in query_embeddings:\n",
    "        distances, indices = index.search(np.expand_dims(query_embedding, axis=0), top_k)\n",
    "        print(\"Top Matches:\")\n",
    "        for dist, idx in zip(distances[0], indices[0]):\n",
    "            if idx >= 0:\n",
    "                match_metadata = photo_ids[idx]\n",
    "                print(f\"Original Image: {match_metadata['original_image']}, \"\n",
    "                      f\"Cropped Face: {match_metadata['cropped_face']}, Distance: {dist}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26bb4625-3ce0-4d2f-a198-878bb99661c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FAISS index from faiss_index.bin\n",
      "Loaded metadata from photo_ids.json\n",
      "Top Matches:\n",
      "Original Image: 1F2A5973.JPG, Cropped Face: 1F2A5973_face_1.jpg, Distance: 12.011140823364258\n",
      "Original Image: _SAN4237.JPG, Cropped Face: _SAN4237_face_2.jpg, Distance: 56.65167999267578\n",
      "Original Image: _SAN4171.JPG, Cropped Face: _SAN4171_face_1.jpg, Distance: 92.5196762084961\n",
      "Original Image: 1F2A5501.JPG, Cropped Face: 1F2A5501_face_8.jpg, Distance: 103.70606231689453\n",
      "Original Image: _SAN4171.JPG, Cropped Face: _SAN4171_face_4.jpg, Distance: 105.64873504638672\n"
     ]
    }
   ],
   "source": [
    "# Paths to stored data\n",
    "faiss_index_path = \"faiss_index.bin\"\n",
    "metadata_path = \"photo_ids.json\"\n",
    "\n",
    "# Query image\n",
    "query_image = \"img_3.png\"\n",
    "\n",
    "# Search for similar faces\n",
    "search_similar_faces(query_image, faiss_index_path, metadata_path, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8cde4-d7fb-425c-93ce-1f8697584e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
